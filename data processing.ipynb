{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python program\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 5.69k/5.69k [00:00<00:00, 6.14MB/s]\n",
      "Downloading data: 100%|██████████| 149M/149M [00:56<00:00, 2.63MB/s] \n",
      "Downloading data: 100%|██████████| 133M/133M [00:25<00:00, 5.18MB/s] \n",
      "Generating train split: 100%|██████████| 3680/3680 [00:00<00:00, 5387.45 examples/s]\n",
      "Generating test split: 100%|██████████| 3669/3669 [00:00<00:00, 6737.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Function to process datasets and extract image paths and labels\n",
    "def process_dataset(dataset_name, split='train', image_column='image', label_column='label_cat_dog'):\n",
    "    dataset = load_dataset(dataset_name, split=split, download_mode='force_redownload')\n",
    "    images_and_labels = [{'image': entry[image_column], 'label': str(entry[label_column])} for entry in dataset]\n",
    "    return images_and_labels\n",
    "\n",
    "# Initialize list to store all data\n",
    "all_data = []\n",
    "\n",
    "# Process each dataset\n",
    "# Oxford-IIIT Pet Dataset\n",
    "all_data.extend(process_dataset('visual-layer/oxford-iiit-pet-vl-enriched'))\n",
    "\n",
    "# Stanford Cars Dataset\n",
    "#all_data.extend(process_dataset('Multimodal-Fatima/StanfordCars_train'))\n",
    "\n",
    "# FGVC Aircraft Dataset\n",
    "#all_data.extend(process_dataset('Multimodal-Fatima/FGVC_Aircraft_train'))\n",
    "\n",
    "# Food101 Dataset\n",
    "#all_data.extend(process_dataset('ethz/food101'))\n",
    "\n",
    "# Birdsnap Dataset\n",
    "#all_data.extend(process_dataset('Multimodal-Fatima/Birdsnap_train'))\n",
    "\n",
    "# VGG Flowers Dataset\n",
    "#all_data.extend(process_dataset('GATE-engine/vggflowers'))\n",
    "\n",
    "# Imagenette Dataset\n",
    "#all_data.extend(process_dataset('frgfm/imagenette'))\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "#df_combined = pd.DataFrame(all_data)\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "#combined_dataset = Dataset.from_pandas(df_combined)\n",
    "\n",
    "# Save the combined dataset\n",
    "#combined_dataset.save_to_disk('combined_dataset')\n",
    "\n",
    "# Print out the number of images and labels to verify\n",
    "#print(f\"Total number of images: {len(combined_dataset)}\")\n",
    "#print(f\"Sample data: {combined_dataset[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=389x500>,\n",
       "  'label': 'cat'},\n",
       " {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x500>,\n",
       "  'label': 'dog'},\n",
       " {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375>,\n",
       "  'label': 'dog'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "all_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import io\n",
    "\n",
    "def process_and_extract_imagenette(dataset_name, label_prefix, target_format='JPEG'):\n",
    "    dataset = load_dataset(dataset_name, split='train', download_mode='force_redownload')\n",
    "    images_and_labels = []\n",
    "\n",
    "    for entry in dataset:\n",
    "        image = entry['image']\n",
    "        label = entry['label']\n",
    "\n",
    "        # Convert image to PIL Image if it's not already\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.open(io.BytesIO(image))\n",
    "\n",
    "        # Convert image to target format\n",
    "        with io.BytesIO() as buffer:\n",
    "            image = image.convert('RGB')\n",
    "            image.save(buffer, format=target_format)\n",
    "            image_bytes = buffer.getvalue()\n",
    "\n",
    "        images_and_labels.append({'image': image_bytes, 'label': f\"{label_prefix}_{label}\"})\n",
    "\n",
    "    return images_and_labels\n",
    "\n",
    "all_data3 = process_and_extract_imagenette('frgfm/imagenette', 'imagenette')\n",
    "\n",
    "# `all_data3` now contains the processed imagenette dataset\n",
    "print(f\"Processed imagenette dataset contains {len(all_data3)} entries.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
