{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in f:\\python program\\lib\\site-packages (3.45.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in f:\\python program\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in f:\\python program\\lib\\site-packages (from gradio) (5.1.1)\n",
      "Requirement already satisfied: fastapi in f:\\python program\\lib\\site-packages (from gradio) (0.103.2)\n",
      "Requirement already satisfied: ffmpy in f:\\python program\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.5.3 in f:\\python program\\lib\\site-packages (from gradio) (0.5.3)\n",
      "Requirement already satisfied: httpx in f:\\python program\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in f:\\python program\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in f:\\python program\\lib\\site-packages (from gradio) (6.1.0)\n",
      "Requirement already satisfied: jinja2<4.0 in f:\\python program\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in f:\\python program\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in f:\\python program\\lib\\site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy~=1.0 in f:\\python program\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in f:\\python program\\lib\\site-packages (from gradio) (3.9.7)\n",
      "Requirement already satisfied: packaging in f:\\python program\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in f:\\python program\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in f:\\python program\\lib\\site-packages (from gradio) (10.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in f:\\python program\\lib\\site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: pydub in f:\\python program\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in f:\\python program\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in f:\\python program\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in f:\\python program\\lib\\site-packages (from gradio) (2.32.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in f:\\python program\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in f:\\python program\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in f:\\python program\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in f:\\python program\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in f:\\python program\\lib\\site-packages (from gradio-client==0.5.3->gradio) (2023.9.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in f:\\python program\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
      "Requirement already satisfied: toolz in f:\\python program\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in f:\\python program\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in f:\\python program\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\python program\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\python program\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in f:\\python program\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in f:\\python program\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in f:\\python program\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\python program\\lib\\site-packages (from requests~=2.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\python program\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\python program\\lib\\site-packages (from requests~=2.0->gradio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\python program\\lib\\site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click>=7.0 in f:\\python program\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in f:\\python program\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in f:\\python program\\lib\\site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in f:\\python program\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in f:\\python program\\lib\\site-packages (from httpx->gradio) (0.18.0)\n",
      "Requirement already satisfied: sniffio in f:\\python program\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: colorama in f:\\python program\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in f:\\python program\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in f:\\python program\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in f:\\python program\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in f:\\python program\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.3)\n",
      "Requirement already satisfied: six>=1.5 in f:\\python program\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)  # Adjust based on output size from conv layers\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))  # Conv Layer 1\n",
    "        x = self.pool((nn.ReLU()(self.conv2(x))))  # Conv Layer 2\n",
    "        x = x.view(-1, 32 * 64 * 64)  # Flatten for fully connected layer\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "# Assuming your CNN class definition is available here\n",
    "# Define a function to load models from saved files\n",
    "def load_client_models(num_clients):\n",
    "    local_models = []\n",
    "    for i in range(num_clients):\n",
    "        model = CNN(num_classes=10)  # Replace `10` with your actual number of classes\n",
    "        model.load_state_dict(torch.load(f\"client models/client_{i+1}.pth\"))\n",
    "        local_models.append(model)\n",
    "    return local_models\n",
    "\n",
    "# Load models trained in the last round, assuming 5 clients and last round being the 5th\n",
    "local_models = load_client_models(num_clients=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.45.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "\n",
    "# Define transformations to resize and normalize uploaded images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Provided label mapping\n",
    "label_names = ['cat', 'dog', 'bird', 'fish', 'car', 'aircraft', 'flower', 'truck', 'parachute', 'mushroom']\n",
    "label_to_index = {label: idx for idx, label in enumerate(label_names)}\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_custom_batch(images, labels):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    preprocessed_images = torch.stack([transform(img) for img in images]).to(device)\n",
    "    \n",
    "    client_accuracies = {}\n",
    "    processed_info = []\n",
    "\n",
    "    for idx, client_model in enumerate(local_models):\n",
    "        client_model.eval()\n",
    "        client_model.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = client_model(preprocessed_images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert predictions to list\n",
    "        predictions = predicted.cpu().numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        correct = (predicted.cpu() == torch.tensor(labels)).sum().item()\n",
    "        accuracy = correct / len(labels) if len(labels) > 0 else 0\n",
    "        client_accuracies[f\"Client {idx + 1} Accuracy\"] = f\"{accuracy * 100:.2f}%\"\n",
    "        \n",
    "        # Create processed info for each client\n",
    "        client_info = []\n",
    "        for i in range(len(images)):\n",
    "            client_info.append({\n",
    "                \"filename\": f\"Image {i + 1}\",  # Placeholder for filenames if needed\n",
    "                \"label\": int(labels[i]),  # Ensure label is an integer\n",
    "                \"prediction\": int(predictions[i]),  # Ensure prediction is an integer\n",
    "                \"label_name\": label_names[labels[i]],  # Optional: Include the string name of the label\n",
    "                \"prediction_name\": label_names[predictions[i]]  # Optional: Include the string name of the prediction\n",
    "            })\n",
    "\n",
    "        # Add client information to processed_info\n",
    "        processed_info.append({\n",
    "            \"client\": f\"Client {idx + 1}\",\n",
    "            \"info\": client_info\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"Client Accuracies\": client_accuracies,\n",
    "        \"Processed Information\": processed_info\n",
    "    }\n",
    "\n",
    "# Gradio Interface function\n",
    "def gradio_interface(files):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images and extract labels from filenames\n",
    "    for file in files:\n",
    "        try:\n",
    "            img = Image.open(file.name).convert(\"RGB\")\n",
    "            images.append(img)\n",
    "\n",
    "            # Extract label from the filename (string before underscore)\n",
    "            label_str = os.path.basename(file.name).split('_')[0]\n",
    "            if label_str in label_to_index:\n",
    "                labels.append(label_to_index[label_str])\n",
    "            else:\n",
    "                raise ValueError(f\"Label '{label_str}' not recognized.\")\n",
    "        except (UnidentifiedImageError, ValueError) as e:\n",
    "            print(f\"Error processing file {file.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not images:\n",
    "        return {\"error\": \"No valid images were uploaded. Please upload image files only.\"}\n",
    "\n",
    "    if len(labels) != len(images):\n",
    "        return {\"error\": \"The number of labels does not match the number of images.\"}\n",
    "\n",
    "    return evaluate_custom_batch(images, labels)\n",
    "\n",
    "# Launch the Gradio UI\n",
    "gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.File(label=\"Upload Images\", type=\"file\", file_count=\"multiple\"),\n",
    "    outputs=\"json\",\n",
    "    title=\"Federated Learning Client Evaluation\",\n",
    "    description=\"Upload a batch of images to evaluate client model accuracy based on the labels extracted from filenames.\",\n",
    "    allow_flagging=\"never\",\n",
    "    live=False\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
