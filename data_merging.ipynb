{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Step 1: Load the datasets from Hugging Face\n",
    "# Make sure you have the necessary datasets in your Hugging Face account\n",
    "aircraft_dataset = load_dataset(\"AnnantJain/aircraft\")\n",
    "birds_dataset = load_dataset(\"AnnantJain/birds\")\n",
    "imagenette_dataset = load_dataset(\"AnnantJain/imagenette\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dataset = load_dataset(\"AnnantJain/cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_cat_dataset = load_dataset(\"AnnantJain/oxford_iiit_pet1\")\n",
    "flower_dataset = load_dataset(\"AnnantJain/vggflowers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_dataset = load_dataset(\"AnnantJain/mushroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec8ca87ce441deaa4578ed21b7d46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Subset the required number of images per label\n",
    "#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\n",
    "# Subset 1200 images for 'aircraft' label\n",
    "client1_aircraft = aircraft_dataset['train'].shuffle(seed=42).select(range(720))\n",
    "\n",
    "# Subset 1000 images for 'bird' label\n",
    "client1_birds = birds_dataset['train'].shuffle(seed=42).select(range(450))\n",
    "\n",
    "# Filter 'parachute' images from imagenette dataset and select 800 samples\n",
    "client1_parachutes = imagenette_dataset.filter(lambda x: x['label'] == 'parachute').shuffle(seed=42).select(range(270))\n",
    "\n",
    "client1_flower = flower_dataset['train'].shuffle(seed=42).select(range(360))\n",
    "\n",
    "\n",
    "# Step 3: Merge the datasets into one for Client 1\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "client1_dataset = concatenate_datasets([client1_aircraft, client1_birds, client1_parachutes, client1_flower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e4d45a70b7426ea830d2e1cfda1ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd8c30175344276bf9c05f1e6b8eb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/13394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459b894e6d6d40bead0d802fd336222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client2_car = car_dataset['train'].shuffle(seed=42).select(range(900))\n",
    "client2_fish = imagenette_dataset.filter(lambda x: x['label'] == 'fish').shuffle(seed=42).select(range(720))\n",
    "client2_aircraft = aircraft_dataset['train'].shuffle(seed=42).select(range(720,1320))\n",
    "client2_truck = imagenette_dataset.filter(lambda x: x['label'] == 'truck').shuffle(seed=42).select(range(405))\n",
    "client2_dog = dog_cat_dataset['train'].filter(lambda x: x['label'] == 'dog').shuffle(seed=42).select(range(375))\n",
    "from datasets import concatenate_datasets\n",
    "client2_dataset = concatenate_datasets([client2_car, client2_fish, client2_aircraft, client2_truck, client2_dog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client3_birds = birds_dataset['train'].shuffle(seed=42).select(range(450,1314))\n",
    "client3_parachutes = imagenette_dataset.filter(lambda x: x['label'] == 'parachute').shuffle(seed=42).select(range(270, 798))\n",
    "client3_cat = dog_cat_dataset['train'].filter(lambda x: x['label'] == 'cat').shuffle(seed=42).select(range(432))\n",
    "client3_car = car_dataset['train'].shuffle(seed=42).select(range(800,1184))\n",
    "from datasets import concatenate_datasets\n",
    "client3_fish = imagenette_dataset.filter(lambda x: x['label'] == 'fish').shuffle(seed=42).select(range(720, 960))\n",
    "client3_dataset = concatenate_datasets([client3_cat, client3_birds, client3_car, client3_fish, client3_parachutes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client4_cat = dog_cat_dataset['train'].filter(lambda x: x['label'] == 'cat').shuffle(seed=42).select(range(432, 932))\n",
    "client4_mushroom = mushroom_dataset['train'].shuffle(seed=42).select(range(400))\n",
    "client4_flower = flower_dataset['train'].shuffle(seed=42).select(range(360, 660))\n",
    "client4_dog = dog_cat_dataset['train'].filter(lambda x: x['label'] == 'dog').shuffle(seed=42).select(range(375, 775))\n",
    "client4_birds = birds_dataset['train'].shuffle(seed=42).select(range(1314, 1514))\n",
    "client4_aircraft = aircraft_dataset['train'].shuffle(seed=42).select(range(1320, 1520))\n",
    "from datasets import concatenate_datasets\n",
    "client4_dataset = concatenate_datasets([client4_dog, client4_flower, client4_cat, client4_mushroom, client4_aircraft, client4_birds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "client5_flower = flower_dataset['train'].shuffle(seed=7).select(range(660, 1460))\n",
    "client5_truck = imagenette_dataset.filter(lambda x: x['label'] == 'truck').shuffle(seed=42).select(range(405, 1205))\n",
    "client5_mushroom = mushroom_dataset['train'].shuffle(seed=42).select(range(400, 1040))\n",
    "client5_dog = dog_cat_dataset['train'].filter(lambda x: x['label'] == 'dog').shuffle(seed=42).select(range(775, 1095))\n",
    "client5_parachutes = imagenette_dataset.filter(lambda x: x['label'] == 'parachute').shuffle(seed=42).select(range( 798, 1118))\n",
    "client5_fish = imagenette_dataset.filter(lambda x: x['label'] == 'fish').shuffle(seed=42).select(range(960, 1280))\n",
    "client5_dataset = concatenate_datasets([client5_dog, client5_mushroom, client5_truck, client5_flower, client5_parachutes, client5_fish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import ImageFilter\n",
    "\n",
    "def add_noise(image):\n",
    "    # Convert PIL image to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(0, 27, img_array.shape)  # mean = 0, stddev = 27\n",
    "    noisy_img = img_array + noise\n",
    "    noisy_img = np.clip(noisy_img, 0, 255)  \n",
    "    \n",
    "\n",
    "    noisy_image = Image.fromarray(noisy_img.astype('uint8'))\n",
    "    return noisy_image\n",
    "\n",
    "def blur_image(image):\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius=2.2))  # Applying slight blur\n",
    "\n",
    "def augment_image(image):\n",
    "    # Randomly choose the type of noise\n",
    "    if random.choice([True, False]):\n",
    "        return add_noise(image)\n",
    "    else:\n",
    "        return blur_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdff175f4864dfca419a302f5570e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client5_dataset = client5_dataset.shuffle(seed=12)\n",
    "\n",
    "clean_images = client5_dataset.select(range(1344))  \n",
    "noisy_images = client5_dataset.select(range(1344, 3200)) \n",
    "\n",
    "noisy_images = noisy_images.map(lambda example: {'image': augment_image(example['image'])}, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019b320174224459a627fb7774eb79db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d536cebe9224d85a6e8e24ccaa1bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ca71871e2f4afbbd82557ebbf7464b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134c05c0a4c24ef990de27136e7600cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c35f3342c3c4211b3915609948fc818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a65edc6c5ad465c81fbccee4d50f58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/AnnantJain/client5_federated_dataset_modified/commit/7c5891344ef94fbbed23b55c9b9eada326660b49', commit_message='Upload dataset', commit_description='', oid='7c5891344ef94fbbed23b55c9b9eada326660b49', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of images and samples for test/train splits\n",
    "total_images = len(clean_images) + len(noisy_images)\n",
    "test_size = int(0.15 * total_images) \n",
    "train_size = total_images - test_size\n",
    "\n",
    "noisy_test_size = int(0.60 * test_size)  # 60% of test set should be noisy\n",
    "clean_test_size = test_size - noisy_test_size  # 40% of test set should be clean\n",
    "\n",
    "clean_images = clean_images.shuffle(seed=42)\n",
    "noisy_images = noisy_images.shuffle(seed=42)\n",
    "\n",
    "clean_test_split = clean_images.select(range(clean_test_size))\n",
    "noisy_test_split = noisy_images.select(range(noisy_test_size))\n",
    "clean_train_split = clean_images.select(range(clean_test_size, len(clean_images)))\n",
    "noisy_train_split = noisy_images.select(range(noisy_test_size, len(noisy_images)))\n",
    "\n",
    "train_images = concatenate_datasets([clean_train_split, noisy_train_split])\n",
    "test_images = concatenate_datasets([clean_test_split, noisy_test_split])\n",
    "\n",
    "new_dataset = DatasetDict({\n",
    "    'train': train_images,\n",
    "    'test': test_images\n",
    "})\n",
    "\n",
    "new_dataset.push_to_hub(\"AnnantJain/client5_federated_dataset_modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "final_client1_dict = DatasetDict({\n",
    "    'clean': clean_images,\n",
    "    'noisy': noisy_images\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711a1e54a7d047afa0129c7502d25414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client2_dataset = client2_dataset.shuffle(seed=8)\n",
    "\n",
    "clean_images2 = client2_dataset.select(range(736))  \n",
    "noisy_images2 = client2_dataset.select(range(736, 2296))  \n",
    "\n",
    "# Apply noise to the noisy_images set\n",
    "noisy_images2 = noisy_images2.map(lambda example: {'image': augment_image(example['image'])}, batched=False)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_client2_dict = DatasetDict({\n",
    "    'clean': clean_images2,\n",
    "    'noisy': noisy_images2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136d71c5064c465eb9683f2adeb4f8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "client3_dataset = client3_dataset.shuffle(seed=8)\n",
    "clean_images3 = client3_dataset.select(range(800))  \n",
    "noisy_images3 = client3_dataset.select(range(800, 2000))  \n",
    "\n",
    "noisy_images3 = noisy_images3.map(lambda example: {'image': augment_image(example['image'])}, batched=False)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_client3_dict = DatasetDict({\n",
    "    'clean': clean_images3,\n",
    "    'noisy': noisy_images3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13737d7acf1a4727ad66482775434f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client4_dataset = client4_dataset.shuffle(seed=8)\n",
    "\n",
    "clean_images4 = client4_dataset.select(range(500))  \n",
    "noisy_images4 = client4_dataset.select(range(500, 1800)) \n",
    "\n",
    "noisy_images4 = noisy_images4.map(lambda example: {'image': augment_image(example['image'])}, batched=False)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_client4_dict = DatasetDict({\n",
    "    'clean': clean_images4,\n",
    "    'noisy': noisy_images4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124f5ef55840440ba8ca4dd2d72404e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "client5_dataset = client5_dataset.shuffle(seed=8)\n",
    "\n",
    "clean_images5 = client5_dataset.select(range(1344)) \n",
    "noisy_images5 = client5_dataset.select(range(1344, 3200))  \n",
    "noisy_images5 = noisy_images5.map(lambda example: {'image': augment_image(example['image'])}, batched=False)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_client5_dict = DatasetDict({\n",
    "    'clean': clean_images5,\n",
    "    'noisy': noisy_images5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad891bc4c8c4010b75818d365abcec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c707139100a4499cbd21a90299a6d4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70390ddf4284e30b738756d2298c131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42f5a730b9f499db380378a9653232c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fbe6320de24783954c7fa9c4382c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ac664314b64959ab98972467d6f062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cfe8f31ab344b5aa08608c8a5c2a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61e6043d33548618dd9dbe45f50c0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/AnnantJain/client5_federated_dataset/commit/964b9bdcebf5ef07692d479c73d12764a2719a5a', commit_message='Upload dataset', commit_description='', oid='964b9bdcebf5ef07692d479c73d12764a2719a5a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "final_client5_dict.push_to_hub(\"AnnantJain/client5_federated_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e40c3db7584ff7a12ef17118aca459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6652cf4815e741ccac9270876e92eab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e1da3d7b8f4a88ba292dba668d746b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 dataset has been uploaded to Hugging Face Hub!\n"
     ]
    }
   ],
   "source": [
    "#  Push the merged dataset to your Hugging Face Hub\n",
    "from datasets import DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "client5_dataset_dict = DatasetDict({'train': client5_dataset})\n",
    "\n",
    "repo_name = \"AnnantJain/client5_dataset\"\n",
    "client5_dataset_dict.push_to_hub(repo_name)\n",
    "print(\"Client 5 dataset has been uploaded to Hugging Face Hub!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset AnnantJain/client5_federated_dataset_modified has been deleted.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "token='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'\n",
    "def delete_dataset(repo_id):\n",
    "    api = HfApi()\n",
    "    try:\n",
    "        # Delete the dataset repository\n",
    "        api.delete_repo(repo_id, repo_type='dataset')\n",
    "        print(f\"Dataset {repo_id} has been deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Usage\n",
    "repo_id = 'AnnantJain/client5_federated_dataset_modified' \n",
    "delete_dataset(repo_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
